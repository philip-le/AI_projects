{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.261314Z",
     "start_time": "2020-05-04T22:03:26.253372Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set_style('whitegrid')\n",
    "from collections import Counter\n",
    "\n",
    "from pomegranate import *\n",
    "\n",
    "corpus_index = 2\n",
    "DAMPING = 0.85\n",
    "SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.277463Z",
     "start_time": "2020-05-04T22:03:26.266644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/philip/Learning/Computer_Science/CS50_Python/Projects/pagerank'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.291792Z",
     "start_time": "2020-05-04T22:03:26.280677Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def crawl(directory):\n",
    "    \"\"\"\n",
    "    Parse a directory of HTML pages and check for links to other pages.\n",
    "    Return a dictionary where each key is a page, and values are\n",
    "    a list of all other pages in the corpus that are linked to by the page.\n",
    "    \"\"\"\n",
    "    pages = dict()\n",
    "\n",
    "    # Extract all links from HTML files\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".html\"):\n",
    "            continue\n",
    "        with open(os.path.join(directory, filename)) as f:\n",
    "            contents = f.read()\n",
    "            links = re.findall(r\"<a\\s+(?:[^>]*?)href=\\\"([^\\\"]*)\\\"\", contents)\n",
    "            pages[filename] = set(links) - {filename}\n",
    "\n",
    "    # Only include links to other pages in the corpus\n",
    "    for filename in pages:\n",
    "        pages[filename] = set(\n",
    "            link for link in pages[filename]\n",
    "            if link in pages\n",
    "        )\n",
    "\n",
    "    return pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.301787Z",
     "start_time": "2020-05-04T22:03:26.295262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithms.html': {'programming.html', 'recursion.html'},\n",
       " 'programming.html': {'c.html', 'python.html'},\n",
       " 'recursion.html': set(),\n",
       " 'python.html': {'ai.html', 'programming.html'},\n",
       " 'ai.html': {'algorithms.html', 'inference.html'},\n",
       " 'logic.html': {'inference.html'},\n",
       " 'inference.html': {'ai.html'},\n",
       " 'c.html': {'programming.html'}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = crawl(f'corpus{corpus_index}')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.307579Z",
     "start_time": "2020-05-04T22:03:26.303327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"class\" :\"Distribution\",\n",
       "    \"dtype\" :\"str\",\n",
       "    \"name\" :\"DiscreteDistribution\",\n",
       "    \"parameters\" :[\n",
       "        {\n",
       "            \"algorithms.html\" :0.125,\n",
       "            \"programming.html\" :0.125,\n",
       "            \"recursion.html\" :0.125,\n",
       "            \"python.html\" :0.125,\n",
       "            \"ai.html\" :0.125,\n",
       "            \"logic.html\" :0.125,\n",
       "            \"inference.html\" :0.125,\n",
       "            \"c.html\" :0.125\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" :false\n",
       "}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the starting probability for which page to stay\n",
    "start = DiscreteDistribution({\n",
    "    page: 1/len(corpus)     for page in corpus\n",
    "})\n",
    "\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.315662Z",
     "start_time": "2020-05-04T22:03:26.309069Z"
    }
   },
   "outputs": [],
   "source": [
    "# states = {page: State(DiscreteDistribution({'yes': 0.5, 'no': 0.5}), name=page)  \n",
    "#               for page in corpus}\n",
    "# states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.323509Z",
     "start_time": "2020-05-04T22:03:26.317594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define transition model\n",
    "\n",
    "transition_list = []\n",
    "lc = len(corpus)\n",
    "\n",
    "for page in corpus:\n",
    "    if len(corpus[page]) == 0:\n",
    "        for next_page in corpus:\n",
    "            transition_list.append([page, next_page, 1/lc])\n",
    "    else:\n",
    "        \n",
    "        for next_page in corpus:\n",
    "            if next_page in corpus[page]:\n",
    "                transition_list.append([page, next_page, DAMPING/len(corpus[page])+(1-DAMPING)/lc])\n",
    "            else:\n",
    "                transition_list.append([page, next_page, (1-DAMPING)/lc])\n",
    "\n",
    "transitions = ConditionalProbabilityTable(transition_list, [start])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:26.344953Z",
     "start_time": "2020-05-04T22:03:26.326037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Markov chain\n",
    "model = MarkovChain([start, transitions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:03:30.595922Z",
     "start_time": "2020-05-04T22:03:26.346992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('programming.html', 0.22835),\n",
       " ('ai.html', 0.18899),\n",
       " ('inference.html', 0.13008),\n",
       " ('c.html', 0.12296),\n",
       " ('python.html', 0.12243),\n",
       " ('algorithms.html', 0.10808),\n",
       " ('recursion.html', 0.07182),\n",
       " ('logic.html', 0.02729)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 100000 states from chain\n",
    "result = [(x[0], x[1]/SAMPLES) for x in Counter(model.sample(SAMPLES)).most_common()]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('deep_learn_py3': virtualenv)",
   "language": "python",
   "name": "python36564bitdeeplearnpy3virtualenvc447f694d85b489d81e265f8e2065388"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
